# SQL Data Warehouse - Proyecto End-to-End ğŸ—ï¸ğŸ“Š

Este repositorio documenta la construcciÃ³n de un **Data Warehouse Moderno** desde cero utilizando **SQL Server**. El proyecto sigue las mejores prÃ¡cticas de ingenierÃ­a de datos, implementando una arquitectura por capas (Medallion Architecture) y procesos ETL robustos para transformar datos crudos en insights de negocio listos para el anÃ¡lisis.

Basado en el tutorial de [Data with Baraa](https://www.youtube.com/watch?v=9GVqKuTVANE).

---

## ğŸ“‹ DescripciÃ³n del Proyecto

El objetivo principal es consolidar datos de ventas dispersos de dos sistemas fuente distintos (**ERP** y **CRM**) en un almacÃ©n de datos centralizado. Esto permite a los analistas de negocio realizar reportes histÃ³ricos, anÃ¡lisis de tendencias y tomar decisiones basadas en una "Ãºnica fuente de verdad".

### Objetivos Clave:
* **Ingesta de Datos:** Cargar datos desde archivos CSV (simulando exportaciones de sistemas) a SQL Server.
* **Arquitectura de MedallÃ³n:** Implementar capas Bronce, Plata y Oro.
* **Limpieza y Calidad (Data Quality):** Normalizar, limpiar y enriquecer datos.
* **Modelado Dimensional:** Crear un esquema de estrella (Star Schema) optimizado para BI.
* **HistorizaciÃ³n:** Manejo de dimensiones cambiantes (SCD) y preservaciÃ³n de datos histÃ³ricos.

---

## ğŸ—ï¸ Arquitectura de Datos

El proyecto utiliza la **Arquitectura MedallÃ³n (Multi-Hop Architecture)** para garantizar la calidad y trazabilidad del dato:

![Architecture Diagram](https://i.imgur.com/placeholder-diagram.png) *(Puedes subir tu propio diagrama aquÃ­)*

### 1. ğŸ¥‰ Capa Bronce (Raw Layer)
* **Objetivo:** Ingesta rÃ¡pida de datos crudos "tal cual" llegan de la fuente.
* **Estrategia de Carga:** Full Load (Truncate & Insert).
* **Transformaciones:** Ninguna. Se mantiene la estructura original para auditorÃ­a.
* **Tablas:** `bronze.crm_cust_info`, `bronze.erp_loc_a101`, etc.

### 2. ğŸ¥ˆ Capa Plata (Silver Layer)
* **Objetivo:** Datos limpios, estandarizados y conformados.
* **Transformaciones:**
    * Manejo de nulos y duplicados.
    * EstandarizaciÃ³n de nombres (ej. "M" -> "Male").
    * ValidaciÃ³n de fechas y rangos.
    * DerivaciÃ³n de nuevas columnas.
* **LÃ³gica:** Se aplica lÃ³gica tÃ©cnica de limpieza, pero no reglas de negocio complejas de agregaciÃ³n.

### 3. ğŸ¥‡ Capa Oro (Gold Layer)
* **Objetivo:** Datos listos para consumo de negocio y herramientas de BI (PowerBI, Tableau).
* **Modelo:** **Star Schema** (Esquema de Estrella).
* **Componentes:**
    * **Dimensiones:** `dim_customers`, `dim_products`.
    * **Hechos:** `fact_sales`.
* **Transformaciones:** Modelado dimensional, creaciÃ³n de claves subrogadas (Surrogate Keys), agregaciones y cruces finales.

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

* **Base de Datos:** Microsoft SQL Server.
* **Lenguaje:** T-SQL (Transact-SQL).
* **Herramienta GUI:** SQL Server Management Studio (SSMS).
* **DiseÃ±o de Diagramas:** draw.io.
* **Control de Versiones:** Git & GitHub.

---

## ğŸ“‚ Estructura del Repositorio

```text
â”œâ”€â”€ datasets/          # Archivos CSV fuente (ERP y CRM)
â”œâ”€â”€ docs/              # DocumentaciÃ³n (Diagramas ER, Data Dictionary)
â”œâ”€â”€ scripts/           # Scripts SQL
â”‚   â”œâ”€â”€ init_database.sql   # CreaciÃ³n de DB y Schemas
â”‚   â”œâ”€â”€ bronze/             # DDL y Stored Procedures capa Bronce
â”‚   â”œâ”€â”€ silver/             # DDL y Stored Procedures capa Plata
â”‚   â””â”€â”€ gold/               # Vistas y DDL capa Oro
â””â”€â”€ tests/             # Scripts de validaciÃ³n y Data Quality Checks
````

-----

## ğŸš€ CÃ³mo ejecutar este proyecto

1.  **Prerrequisitos:** Tener instalado SQL Server y SSMS.
2.  **Clonar el repo:**
    ```bash
    git clone [https://github.com/tu-usuario/sql-data-warehouse-project.git](https://github.com/tu-usuario/sql-data-warehouse-project.git)
    ```
3.  **Inicializar BD:** Ejecutar `scripts/init_database.sql` para crear la base de datos y los esquemas (`bronze`, `silver`, `gold`).
4.  **Cargar Datos (ETL):**
      * Ejecutar los scripts de la carpeta `scripts/bronze` para cargar los CSV.
      * Ejecutar los Stored Procedures de `scripts/silver` para limpiar y transformar.
      * Crear las vistas de `scripts/gold` para el modelo final.
5.  **Tests:** Ejecutar los queries de la carpeta `tests/` para verificar la consistencia de los datos.

-----

## ğŸ“š Conceptos Aprendidos

  * **ETL vs ELT:** ExtracciÃ³n, carga y transformaciÃ³n masiva usando `BULK INSERT`.
  * **Data Quality:** Uso de tÃ©cnicas como `ISNULL`, `CASE WHEN`, `TRIM`, y validaciones de integridad referencial.
  * **SCD (Slowly Changing Dimensions):** Entendimiento de cÃ³mo manejar cambios en los atributos de las dimensiones.
  * **Separation of Concerns (SoC):** Mantener la lÃ³gica de extracciÃ³n separada de la lÃ³gica de negocio.
  * **Naming Conventions:** Importancia de una nomenclatura estÃ¡ndar (Snake Case) para mantenimiento a largo plazo.

-----

## ğŸ“¢ CrÃ©ditos

Este proyecto fue desarrollado siguiendo el tutorial "SQL Data Warehouse from Scratch" de **Data with Baraa**.

  * [Video Original](https://www.youtube.com/watch?v=9GVqKuTVANE)
  * [Canal de Baraa](https://www.youtube.com/@DataWithBaraa)

<!-- end list -->
